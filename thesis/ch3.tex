%   MSc Business Analytics Dissertation
%
%   Title:     Literature Review
%   Author: Conor Reid
%
%   Chapter 3: Literature Review
%
\chapter{Literature Review}\label{C.LitReview}
\section{Introduction}\label{S.intro3}
{This literature review first presents some of the ways that corporate success can be quantified. This includes how it is defined by \cite{moldovan2015learning}, as well as by others whose approaches may benefit this study. This is followed by an analysis of literature pertaining to the relationship between corporate governance and company performance, again including the work of \cite{moldovan2015learning} as well as other relevant studies. This review finishes with an exploration of literature regarding causation and the statistical techniques used to infer causation. There is also discussion on the issues that arise in attempting to do so, and how they can be addressed. }
\section{Company Performance - Measures and \\ Factors}
{Among the key aspects of this study is the quantifying of corporate success, in a way that accurately   represents good and bad corporate performance. There are many aspects to this. For example, many different financial ratios have been developed that attempted to assign numerical performance ratings to companies taking into account a variety of accounting indictors. \cite {eidleman1995z} states that these ratios are often created by academics, and outlined the patterns they tend follow. He desribes how researchers find a sample of companies that meet some predetermined criterion of failure, as well as another sample of comparable firms (size, industry etc) that differ only in financial health. Common statistical learning can then be used to analyse which ratios can accurately separate the groups. Those which do so are kept, the rest discarded. Weights are assigned to each ratio to reach an aggregate equation. New firms are scored, and real-world performance recorded to measure how useful the new ratios are. \\\\
Blindly following financial ratios is often suboptimal and can be thought of as an over-reliance on simple stock price indicators. Perhaps the inclusion of more varied and diverse measures are required, such as the companies social responsibility commitments, and their impact on the environment. Both may contribute to a more accurate picture of corporate performance, and are discussed below.       }
\subsection{Financial Ratios}
{One of the indicators of corporate performance used by \cite{moldovan2015learning} is Tobin's Q score. This measure was devised by \cite{tobin1969general} who postulated that the combined market value of a given company should be equal to their replacement costs. This is described as the ideal state, with any deviation either way (a ratio above or below 1) warranting investment or the selling of assets. The use of this measure is well established in the literature, by \cite{chung1994simple}, 
\cite{bhagat2008corporate} and \cite{bolton2011unified}. \cite{chung1994simple} state that Tobin's Q plays an important part in financial interactions, and is employed to explain diverse corporate phenomena during the decision making process. \cite{bolton2011unified} used Tobin's Q to propose a model for dynamic investment and risk management and found that investment is best driven by the Q score as well as to the marginal value of liquidity.\\\\
The formal definition of Tobin's Q is given by \cite{chung1994simple} as; 
\begin {equation}\label{TobinQ}
L-R  \quad q = \small {\frac{PREFST + VCOMS + LTDEBT + STDEBT - ADJ}{TOTASST - BKCAP + NETCAP}}
\end{equation}\\
There is debate as to the practically of the Q score. \cite{chung1994simple} go on to state that the Q score is often neglected in real-world situations. One of the reasons they give for this is the complexity of the necessary calculations, and a potential unfamiliarity with its operational intricacies. Another reason is the unavailability of relevant data, particularly with high accuracy and in real-time. To counteract this, they worked to create and test an accurate approximation of Tobin's Q that utilises only basic financial information. They conclude that their approximation is close enough to the more formal definition to be used where more exhaustive calculations are not possible. \\\\
\cite {dybvig2010tobin} criticise Tobin's Q more strongly, stating that it is fundamentally malformed as a measure of corporate performance. They highlight long-serving managers as risk adverse, and who "...can {\it enjoy the quiet life} and underinvest". A logical implication of this is that firms invest less and operate well below their profit-generating capacity and thus reduces their net-present value. However, such is Tobin's Q formulated, underinvestment by a firm increases its Q score. They go on to explain the scores ambiguity, COME BACK TO. \\\\Another measure of corporate success used by \cite{moldovan2015learning} is the Altman Z score, which is often used as a probabilistic measure of whether a company will go into bankruptcy within the next two years. It can also be used more generally as a financial distress measure and to predict corporate defaults. The authors point out that there is much advocacy in the literature for using this measure, and this study was unable to find any that strongly reject its usefulness. The Altman Z score is given as;
\begin {equation}\label{AltmanZScore}
\begin{aligned}
Z \ Score \quad = \quad & 1.2\bigg(\frac{Working \ Capital}{Total \ Assets}\bigg) \ + \\\\
		& 1.4\bigg({\frac{Retained \ Earnings}{Total \ Assets}}\bigg) \ + \\\\
		& 3.3\bigg({\frac{Earnings \ before \ Interest \ and \ Tax}{Total \ Assets}}\bigg) \ + \\\\
		& 0.6\bigg({\frac{Market \ Value \ of \ Equity}{Total \ Liabilities}}\bigg) \ + \\\\
		& 1.0\bigg({\frac{Sales}{Total \ Assets}}\bigg)
\end{aligned}
\end{equation}\\
Among those that support this scores use is \cite {eidleman1995z}, who discusses its use in practice. He begins by highlighting Altman's own tests using the Z score which involved predicting 72\% of bankruptcies two years prior to the event, although the sample size or companies involved are not mentioned. Eidleman argues that the Z score is tried and tested, and;
\begin {quote}
It has been demonstrated to be quite reliable in a variety of contexts and countries. 

\hspace{2cm}---  \cite {eidleman1995z}
\end{quote}
Eidleman also outlines circumstances that warrant corrections and alterations to equation \ref{AltmanZScore}, in order to generalise it beyond its originally intended means. He argues that before being able to use the Z score, one must ensure the company in question is comparable to those involved in Altman's original study. Altman considered manufacturing and small firms in his original analysis, thus corrections must be made before scoring companies in different industries. Eidelman points to two specific circumstances here. \\\\
The first considers privately held companies, whose stocks are no publicly traded meaning term four of equation \ref{AltmanZScore} cannot be calculated. To correct for this, the Z score can be re-estimated using book values of equity. In other words, details from balance sheets published by private firms voluntarily can be used rather than details gleamed from the stock market. Certainly a work-around here is to consider solely publicly traded companies. A consequence of this is that such an analysis would only include companies that are bound by the the corporate governance code in their jurisdiction, which would need to be taken into account in studies such as this one.\\\\ Eidleman's second consideration is for non-manufacturing firms. The fifth term of equation \ref{AltmanZScore}, according to Eidleman, varies significantly by industry. He argues that merchandise firms for example, are significantly less capital intense and thus are much more likely to enjoy higher asset turnover and consequently Z-Scores. Z scores then would be likely to under-predict bankruptcy in these cases. In order to correct for this, a recommendation comes from Altman to eliminate the fifth term and adjust the weights. The adjusted equation \ref{AltmanZScoreAjusted} is shown below;
\begin {equation}\label{AltmanZScoreAjusted}
\begin{aligned}
Z \ Score \quad =  \quad & 6.56\bigg(\frac{Working \ Capital}{Total \ Assets}\bigg) \ + \\\\
		& 3.26\bigg({\frac{Retained \ Earnings}{Total \ Assets}}\bigg) \ + \\\\
		& 6.72\bigg({\frac{Earnings \ before \ Interest \ and \ Tax}{Total \ Assets}}\bigg) \ + \\\\
		& 1.05\bigg({\frac{Market \ Value \ of \ Equity}{Total \ Liabilities}}\bigg) \ \\\\ 
\end{aligned}
\end{equation}\\
Overall, the Altman Z score seems a highly appropriate indicator of corporate financial strength and thus success, and one that should be considered in this study. Consideration will need to be had for the type of industry included in this analysis, that will inform the exact calculation of the Z score itself. }
\subsection{Environmental Considerations}
{As mentioned previously, there is likely much room for improvement in quantifying corporate success beyond financial ratios. One potentially useful alternative is the link between environmental and economic performance, studied by \cite{schaltegger2002link}. The authors present two conflicting viewpoints in this space. The first states that improved environmental performance predominantly causes an increase in operating costs, which in turn negatively effects the profitability of the company. The second viewpoint states the opposite; improving a firms environmental performance in fact induces cost savings, which drives increases in profitability. These viewpoints are visualised in figure \ref{ch3_successAndEnviornment}. 
\begin{figure}[h] 
\centering
\includegraphics[scale = 0.7]{images/ch3_successAndEnviornment.png}
\caption{Potential correlations between corporate environmental protection and economic success.}
\label{ch3_successAndEnviornment}
\end{figure}\\
$ES_0$ represents the current level of economic success (this is described as a certain shareholder value), which decreases as spending in environmental protection increases (through points E and F, to D where non profit can be made). This is the pessimistic view, or the expectation that spending in this space reduces profit making ability to eventual zero. The more optimistic view is represented by the path from $ES_0$ through points A and B to point C (again where no profit is possible). This represents the ideology that some economic gain can be achieved, at least to some degree before tailing off, by being environmentally conscious. \\\\
The authors draw two conclusions from figure \ref{ch3_successAndEnviornment}. First, they argue that environmental performance can vary at a given level of economic success. Secondly, the reverse; that economic success can vary for a given level of environmental protection. These are key points, since it indicates that the former may not be a good predictor for the latter, and that an uplift in economic success is not guaranteed with increased environmental efforts. The authors conclude that the correlation between economic and environmental performance depends on not just company externalities but internal variables which are influenced by management. It is firm management, who moderate this relationship, that must be optimised in order to gain economically. The authors put this forward as an explanatory variable not considered in the literature to this point. \\\\It is natural then to ask how this can be realised in analysis. \cite{schaltegger2002link} suggest two cases from which data may be derived. The first relates to the firms ability to utilise to the full the economic benefits of environmental protection measures. This may materialise in R\&D spending, or other marketing positioning that communicates their efforts and establishes them as industry leaders. The second relates to how this reputation is achieved in practice, by realising the optimal environmental performance for maximum economic success. This can take the form of identifying the most optimal way to reach clean production for example.\\\\
\cite{wahba2008does} also perform research in this area, studying whether the market values corporate environmental responsibility, specifically in an Egyptian context. Similarly to \cite{schaltegger2002link}, the authors acknowledge divided and inconclusive literature on this topic, stating an aim to present empirical evidence on how engagement with environmental responsibility can influence corporate market value. For their analysis they looked at a sample of 156 firms across 19 industries, using firm market value as the dependant variable (interestingly, quantified by Tobin's Q score mentioned previously). Important to note is the authors use of ISO 14000/14001 certification as a proxy for environmental performance. This is recognised by the authors as non-ideal, however this may still have some utility in future research to address the difficulty in quantifying performance in this area. \\\\ \cite{wahba2008does} state that the overall finding of this research is that the market does in fact reward firms for their environmental efforts, by positively influencing that firms Tobin's Q score, but do point to similar issues raised by \cite{schaltegger2002link}. Namely, that a companies decision to reduce their impact on the environment comes with significant cost and that if this is not managed correctly, the economic benefits evaporate.     \\\\
There is clear support in the literature for the presence of a relationship between corporate economic success and environmental performance. \cite{schaltegger2002link} suggest it is the firm management of environmental considerations that influences success, and put this forward as an explanatory variable not yet considered in literature. This theory is supported by \cite{wahba2008does}, who find a strong relationship in this space but with a caveat that management plays a significant role in realising benefits. It remains to be seen exactly how this can be realised in data analysis. }
\subsection{Corporate Social Responsibility}
{Corporate social responsibility, or CSR, is defined by the European Commission as "the responsibility of enterprises for their impacts on society". This is similar to being conscious of environmental impact, but can be generalised to include compliance with established ethical standards and national and international norms. Central to CSR is the creation of shared value between themselves and their stakeholders and the larger society as well as mitigating their possible adverse impacts with those groups. It is natural to consider elements of CSR then, when discussing firm success metrics. \\\\
\cite{orlitzky2003corporate} begin their research in this space by stating 
\begin{quote}
Most theorizing on the relationship between corporate social / environmental performance (CSP) and corporate financial performance (CFP) assumes that the current evidence is too fractured or too variable to draw any generalizable conclusions.

\hspace{2cm}--- \cite{orlitzky2003corporate}
\end{quote}
Their research aims to show this claim is unfounded, and provide a more rigorous methodology for drawing such conclusions. They argue that many authors have attempted to find causal relationships between CSP and CSR, but have failed in part due to a failure to see vital differences between theory and operational applications. They also state that an aim of their research is to aggregate knowledge in the area, and highlight important findings they believe to be overlooked. Meta-analysis have been proven to proved value where a number of disparate and conflicting results mean the field is inconclusive.\\\\
They present a number of hypotheses. They first states that CSP and CFP are positively related, regardless of industry and the context of the given study relating the two. They base this on a number of studies, stating that CSP is a vital form of "good management theory" that boasts competitive advantage by addressing stakeholder concerns quickly and fairly.  Secondly, they hypothesise on the temporal nature of this relationship. They state that there is a bidirectional causality between CSR and CFP. That is, there is a circular casual relationship that governs performance in each area. This is supported by the idea that prior success in CFP facilitates positive engagement in CSP, due to increased responsibility and freedom at the managerial level. \\\\
The third hypothesis put forward by \cite{orlitzky2003corporate} involves the underlying logic behind the correlation between CSP and CFP. The first is that CSP boasts managerial competencies and organisational efficiency, by enabling shared knowledge of the firm's market as well as social and political environments. Secondly they suggest that CSP is a driving factor behind the firm's reputation, and thus elicits significant goodwill from stakeholders. The fourth and final hypothesis put forward involves the methodology used by previous studies to draw conclusions from. The authors here suggest that the variance in results seen across studies can be explained by sampling or measurement error, for example. 
\\\\
In order to support these claims, \cite{orlitzky2003corporate} perform a meta-analysis involving 52 studies across both CSP and CFP, resulting in a total sample size of 33,878 observations on which they perform their analysis. This analysis involves a statistical aggregation technique to be applied, which calculated the cumulative correlations across studies, correcting for variable elements of those studies to reach one "true score correlation ($\rho$)". Using this technique, the authors were able to explain 24\% of the cross-study variance in relation to the observed r value, which they suggest is significant. That is, by controlling for sampling and measurement errors across multiple studies, they could reduce the variation in results by 25\%. They suggest that this, strengthened with other analysis, supports their first hypothesis. }
\section{Corporate Governance and Company Performance}
\subsection{Governance Models}
\subsection{Influence of Governance on Performance}
\section{Inferring Causation}
\subsection{Introduction}
{It is stated ad nauseum in scientific and popular literature that "Correlation does not imply causation" or similar. In statistical analysis, it is tempting to infer causal relationships between features where only correlation has been proven and indeed a significant amount of literature seems to do exactly this. For example, the study of \cite{moldovan2015learning} on which the current study is based, makes string claims as to the relationships between corporate governance and company success. In reality, the authors perform insufficient analysis to support such claims, instead finding correlations worthy of further investigation. \\\\
Interestingly, there is a significant body of research that argues that it is impossible to prove causation. It is said that if all variables that could possibly be causal are considered, causation can be reliably inferred. Of course in practice this is almost never the case, and so issues around $<>$ require advanced techniques to address and potentially overcome.     \\\\
One of the major issues with applying causal research in this domain is the study design. Many studies, particularly in the medical field, are able to take advantage of robust experimental design standards that facilitate a deep and accurate exploration of results. They are able to control for unobserved covariates using randomised trials, and generally have a large degree of control over the statistical parameters of the study. The goal here is often to maintain a treatment and control group, and estimate that treatments effect on outcomes.  \\\\
Outside of such a highly controlled environment, causal inference becomes more difficult where we begin to deal with observational studies. The work of \cite{moldovan2015learning} is such a study, where they authors derived historical data tat was generated outside of their control and tried to uncover relationships within. \cite{esarey2015causal} identifies an interesting problem with this type of work. Often, the act of choosing to be treated has a significant effect on outcomes. He gives the example of education; those who choose to complete higher education may be those who stand to gain from it the most, and so it is difficult to estimate educations effect on income. Similarly in the study of \cite{moldovan2015learning}, it is difficult to assess the benefit of various elements of corporate governance on firm performance due to the self-selecting nature of those who perform well in the former. \\\\
This is a highly complex space, and one that certainly calls for advanced techniques that can mitigate the issues outlined above. The remainder of this section is dedicated to some of these techniques, with discussion of their technicalities and practical applications.  }
\subsection{Matching}
{One approach to bridging the gap between experimental and non-experimental studies is matching, outlined by \cite{stuart2010matching} who considers studies that use observational data that can be divided into treated and non-treated cases. Matching is then used to study the effects of this treatment on some outcome, in a very similar way to standard experimental trials in the medical field for example. He describes first how one of the biggest benefits of randomised experimental studies is that the treated and un-treated groups are guaranteed to be randomly different from one another, on both observed and unobserved covariates (or features that may influence the outcome). That is, such experiments are able to control for factors that have not been explicitly designed for in the experiment. Statistical matching aims to imitate this for observational studies, by balancing the distribution of potentially useful features in the treated and control groups. This is achieved by identifying observations that differ only in treated status, facilitating the analysis of the causal effect of that treatment. In effect this ignores un-observed features, and aims to reduce bias in the distribution of observed features as much as possible. The concept of {\it strong ignorability} is heavy relied upon here, which is to say that it is assumed that all feature that may influence the outcome are being considered. \\\\
\cite {stuart2010matching} identifies matching as a potentially useful mechanism in supervised learning, where the outcome is known and the goal is to estimate its effect. Thus, matching is considered in this study where the treatment can be quantified as fluctuations in various explanatory corporate governance variables (among others) which in turn influence the a firms outcome. \\\\
\cite {stuart2010matching} sets out four key stages in the matching process. They are;
\begin {enumerate}
\item{Defining the measure of {\it closeness}.}
\item{Choosing an appropriate matching method.}
\item{Quality assessment of matched samples, returning to step 1 depending on results.}
\item{Treatment analysis, given the results of Step 3.}
\end{enumerate}
A measure of closeness quantifiably determines whether an observation is a good match for another. This is a crucial aspect to matching, and can be subdivided into two parts. The first involves pruning the dataset features for those to include, taking into consideration {\it strong ignorability}. \cite{stuart2010matching} points out that poor results are expected from using small sets of features, particularly those that pertain solely to a narrow view of that observation (for example, demographic details of individuals). He states that there is little disadvantage in including features that are not actually associated with outcome, albeit a slight increase in variance is expected. Conversely, neglecting a feature that is associated with outcome is very costly, and so it is recommended to include as many features as is practical as a precaution. It is also recommended to do so without relying on observed outcomes, and instead make decisions based on domain knowledge. \\\\
%put in something here about type of variables not to include
The second aspect to closeness is the measure of distance itself, or the similarity between two observations in the data. There are many ways to do this, that vary in the exactness of the match required. \cite{stuart2010matching} argues that exact matching is ideal, but very often unattainable especially with high dimensional data. Requiring a very high degree of exactness leads to observations remaining unmatched which then fall out of consideration, a phenomenon that in turn can lead to more bias than if the matching measure required less exactness. A way to address this is to categorise continuous features, a practice used in calculating the Mahalanobis distance for example which works well with low dimensionality, but poorly with highly non-uniformly distributed features.
\\\\ 
The next stage in the matching process is the choose of matching method, which uses the closeness distance to create the matches themselves. The motivation behind using one method over another lies in the number of observations that remain after matching has taken place, and the relative weights that different individuals receive. One such method is nearest neighbour matching (NNM), which is stated as the most common, most understandable and easiest to implement methods available by \cite{stuart2010matching}. In essence, this method couples a treated and un-treated observation, minimising the distance between the two. Controls can be put in place to dictate the exactness of each match, potentially discarding treated cases if a suitable match is not found. This helps to prevent bad matches, but leads to difficulties in interpreting results. What results from NNM is a data set of similar dimension to the amount of treated cases, which arguably reduces the power of the data. \cite{stuart2010matching} states in response to this that model precision is effected most by the smaller group size in any dataset, and so balancing observations down to this smaller group size should not in fact dramatically reduce it power. 
\\\\
The third stage of the matching process is a quality assessment of the matched samples, which is the most important step according to \cite{stuart2010matching}. The aim here is to rate how balanced the matches set is, where balance refers to the similarity of feature distributions, and the independence of features and treatment status. Poor results here calls for alternative distance measures and matching methods, and so iteration is often required to find the optimal methodology. \cite{stuart2010matching} proposes numerical diagnostics to achieve this step. This involves the inspection of the difference in means of each feature, divided by the standard deviation which gives the {\it standard bias}. This is performed for each feature, as well as their two-way interactions and squares. The author discards other common tests here such as hypothesis tests, due to contextual issues and how balance is interpreted by those tests. 
\\\\
The fourth and final step of the matching process is outcome analysis. It should be noted that matching is not actually a tool used for inferring causation, but rather presents a new dataset that is treated as if sourced through randomised methods.  
\\\\
\cite{king2014balance} also studied matching for casual inference, specifically proposing an approach to optimising balance between treated and un-treated groups and the matched sample size. The issue of a reduction in sample size due to matching was highlight above by \cite{stuart2010matching}, who argued any negative effects were offset by the increased balance between groups. \cite{king2014balance} however argue that practitioners often do see this as an issue, citing manual tweaking that occurs in an effort to optimise sample size and balance or simply the resignation to suboptimal solutions. \cite{king2014balance} then propose a {\it matching frontier}. They claim this fully characterises this trade-off, and allows researchers to evaluate balance as observations are pruned and "simultaneously trade this off against the lower variance produced by larger matched sample sizes".
}

\subsection{Directed Acyclic Graphs}