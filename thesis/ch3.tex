%   MSc Business Analytics Dissertation
%
%   Title:     Aaa Bbbbbbb Cccccccccc
%   Author(s): Xxxxxx Xxxxxxxxx and Yyy Yyyyyyyyy
%
%   Chapter 4: Methodology
%
%   Change Control:
%   When     Who   Ver  What
%   -------  ----  ---  --------------------------------------------------------------
%   11Feb11  AB    0.1  Begun 
%

\chapter{Methodology}\label{C.Methodology}
\section{Introduction}
{This chapter outlines the method followed during this analysis, with a view to explaining the detailed steps taken from stage to stage. The KDD process as outlined by \cite{fayyad1996kdd} was followed where possible, as a well established end-to-end framework for deriving knowledge from raw data. To that end, we first discuss data acquisition and the raw data characteristics. This is followed by a discussion of the preprocessing and reduction required to make this data useable. This includes how missing data and outliers are handled. We then outlined the data mining techniques used, including analysis of the advantages and disadvantages of the various statistical methods and associated software packages available. Following this, we outline in detail the steps taken for each element of this study. That is, the replication of and expansion on the work by \cite{moldovan2015learning} and the application of casual research in this domain. We finish by comparing the ways in which results can be interpreted, including what measures of algorithmic success should be used and so on. Overall, this chapter represents the technical aspect of this study and aims to facilitate the replication of this analysis by future researchers. }
\section{Data Acquisition}
\subsection{Core Data}
{The primary source of data for this study comes from the authors of the paper it extends. Darie Moldovan and Simona Mutu were kind enough to provide us with the data they used in their analysis, sending the complete set and granting permission to use it for out analysis. This has a duel benefit. Firstly, the results from the current analysis can be placed in a much clearer context, since we can directly and numerically identify wether or not the inclusion of auxiliary features or different measures of corporate success pose an advantage. In other words, we do not need to worry about data dependance when comparing the results of this study and the study it seeks to improve on. Secondly, being granted access to a purpose built dataset prior to undertaking this analysis represents a significant catalyst for progress, and surely expedites the process of gaining greater understanding in this domain.}
\subsection{Corporate Social Responsibility}
{The dataset provided by Darie Moldovan and Simona Mutu contains records of 1400 companies, with 52 features. As mentioned previously, these features consider solely corporate governance as a predictor for success, and this study aims to extend this to consider other areas. One such area is corporate social responsibility (CSR).\\\\
--------------
Potential Sources of Data
\begin{enumerate}
\item{Bloomberg? }\\
\url {https://www.library.hbs.edu/docs/bloomberg%20esg%20functionality%20map.pdf}
\item{\url{https://www.csrhub.com/csrhub-meets-your-sustainability-needs/}}
\item{\url{https://www.researchgate.net/post/Are_there_any_publically_available_data_sets_or_sources_that_provide_Corporate_Social_Responsibility_CSR_scores_of_companies2}}
\item{\cite{rahdari2015designing}}
\item{\url{http://financial.thomsonreuters.com/content/dam/openweb/documents/pdf/tr-com-financial/methodology/corporate-responsibility-ratings.pdf}}
\end{enumerate}}
\subsection{Environmental Performance}
{Another area shown to be promising in terms of predicting corporate economic success is the environmental performance of a company. in other words, the measures put in place by a company and efforts made to reduce their footprint on the natural environment may be a good indicator of how successful that company is. \\\\
--------------
Potential Sources of Data
\begin{enumerate}
\item{Bloomberg? }\\
\url {https://www.library.hbs.edu/docs/bloomberg%20esg%20functionality%20map.pdf}
\\
"Bloomberg for Environmental, social and governance data"\\
Looks like you can get "Emissions and Energy Markets" data.
\end{enumerate}
Only research I've read is theoretical. Need to investigate further where data is going to come from here.

}
\section{Data Pre-Processing and Reduction}
{Interestingly, \cite{moldovan2015learning} made the decision to remove any observations in their data that had missing values, or not enough information to calculate key metrics. These emissions are likely justified, since incomplete data (and especially miscalculated metrics) would unfairly skew the properties of that observation and misrepresent it in the data. Any conclusions that were made using these observations could be fundamentally flawed. In the current study, if data cannot be found to complete these records a similar approach will be used. \\\\
\cite{moldovan2015learning} also state that they remove outliers in the data, citing a desire to prevent data errors. We feel this is not convincing evidence that the outliers are fair emissions. It is generally accepted that outliers must be proven to be mistakes at the data collection stage, or invalid in some other way to justify leaving them out of the analysis. Without such justification, outliers are valid data points and may prove crucial to the formulation of a faithful model. While they state that removal in total only discounts 122 observations, this amounts to roughly 8\% of the original dataset. The current study carries out analysis with and without outliers, with a view to inspecting their influence. 
\section{Data Mining, Algorithms and Software}
Notes \\\\
Here, discuss what data mining approaches I'm going to use. Mention using classification algorithms as an alternative to what MM used, and also regression on real-valued Q and Z score.
\begin{itemize}
\item{Use similar to MM - Adaboost M1, J48, Simple Logistic regression, ADTree on same data (and new dataset with other params)}
\item{Don't bin Q and Z score into categories, instead leave as real value. Use regression (Kernel regression?).}
\item{Look into neural nets?  }
\item{For casual research}\\
{\url {https://github.com/akelleh/causality} for the algorithm shown in \cite{pearl1995theory}}
{\url{http://projects.iq.harvard.edu/frontier} for matching method in \cite{king2014balance}}

\end{itemize}
\section{Implementation}
\subsection{Replication and Expanding the Research}
\subsection{Causation}
\section{Interpretation}
Notes\\\\
Here, discuss how I'm going to interpret results. What measures of algorithm performance to use, what weighting's to give to each etc. 
\begin{itemize}
\item{Use similar metric to MM?} \\
ie use precision, sensitivity and specificity, ROC (Receiver operating characteristic) curve.
\item{Confusion matrixes}
\end{itemize}
