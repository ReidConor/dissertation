---
title: "Corporate Goverance and Company Performance"
output:
  pdf_document: default
  html_document: default
---

\newcommand{\boxedcheckmark}
  {{\ooalign{$\Box$\cr\hidewidth$\checkmark$\hidewidth}}}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Project Goals + Status

$\boxedcheckmark$ An initial goal is to acquire the dataset, whether by contacting MM or using Bloomberg terminals available in UCD Quinn and Smurfit, and reproduce some of MMâ€™s results. 
  
&nbsp;&nbsp;&nbsp;&nbsp;  Done
  
  
$\boxedcheckmark$	A central goal is to apply (regularized) regression, and classification-on-regression (i.e. thresholding on the real value predicted by regression) rather than straight classification, as the main analysis, and follow this with a careful discussion of the pros and cons, and the findings (e.g. correlation analysis, both linear and rank correlation). 

&nbsp;&nbsp;&nbsp;&nbsp;  Done

$\boxedcheckmark$	A side goal is to consider alternative features and measures of performance, beyond Z and Q. 

&nbsp;&nbsp;&nbsp;&nbsp;  Tried [Beneish M Score ](https://en.wikipedia.org/wiki/Beneish_M-Score) as a dependent variable. Various ESG variables from Bloomberg as independent variables

$\Box$	A stretch goal is to investigate modern work in causality (Pearl, 2009, King et al., 2016) and attempt to apply it here. Any contribution to the task of proving causality, as opposed to correlation, would be a large contribution.

&nbsp;&nbsp;&nbsp;&nbsp; Implementing [akelleh](https://github.com/akelleh/causality), and [causalTree](https://github.com/susanathey/causalTree). Work needed on specific implementation details. 

\clearpage

# M\&M - Classification
Taking the data, algorithms and hypothesis put forward by MM and replicate results. Data used as is or with manipulations made by M&M. Results as per Table 1 and 2. 

# M\&M - Regression
Taking same data, but not thresholding on dependent variables leaving it as a regression problem. Imputing (multiple, m=5) the data using the mice package. Lasso wont work on data with missing values. Running with just complete cases is an option, but could introduce bias? Also, zero rows in eebp are complete, very small number in sxxp. Tried for complete cases in spx (56 rows).

All results in table 3.    

Included in those results is a regression on the Beneish MScore, which is a measure of how likely it is that the reported earnings of the company have been manipulated. Results are poor in terms of R^2. There is room for more work here (other dependent variables, and include in causal analysis as described below.)

\clearpage

# Causality
## akelleh

### Methodology - Causal Estimation

M&M make 8 statements about the effects of various corporate governance features on either Tobins Q or the Altman Z Score. This is the basis for my work on causal estimation, following this guide - [https://github.com/akelleh/causality/tree/master/causality/estimation](https://github.com/akelleh/causality/tree/master/causality/estimation). The goal is to pick a treatment and outcome, and measure the magnitude of the effect of the former on the latter. Uses propensity matching. 

I've built a MySQL table per statement to test. The manipulations I carry out to prepare each are: 

* Impute the data to remove missing values. Taking just complete cases is infeasable especially for sxxp and eebp data-sets, since there are so few cases without missing data.  

* Scale all columns apart from the treatment and target. Speeds up algorithm run-time. Leaving treatment and target as-is so that the resulting estimated causal effect is in the same units. 


Called using something like;

```{r eval=FALSE}
ATE_results = matcher.estimate_ATE(
  data, 
  treatment, 
  target, 
  {'P.B': 'c', 'Asset':'c', 'Tax':'c', 'P.E':'c'}, #to control for 
  bootstrap=True
)
```

The main issue is how to pick out variables to control for. When I control for all in the dataset, I get an error about perfect separation in the matching stage. 

Results for each of M&M's statements are in table 4. 

My analysis also includes some plotting to show how good the matching process was, in terms of overlap in 1-D between the test and control groups. They need to overlap on the x axis. I think this is a good way to show whether propensity score matching is valid using those variables, but I can't just try every combination to see how the matching performs (I don't think?). Diagrams such as \<over the page\>. I need to find a better way to pick these variables, presumably by picking out ones that are marked as important in the literature? Could also use those marked as important in the classification / regression phase? 


```{r pressure, echo=FALSE, fig.cap="PSM testing - Asset", out.width = '100%'}
knitr::include_graphics("PSM_test.png")
```


\clearpage


### Methodology - Causal DAG
Efforts at constructing a causal DAG as per [https://github.com/akelleh/causality](https://github.com/akelleh/causality), with arrows inferring causal influence. Under the hood, the algorithm is Pearls IC. 

Requires the selection of variables to feed into the algorithm. I haven't figured out a smarter way of doing this, other than picking important variables from the regression analysis plus one of [Tobins Q / Altman Z]. Results looks like
  
   \textcolor{gray}{
  [('Tax', 'P.E', {'arrows': ['Tax', 'P.E', 'P.E'], 'marked': False}),
   ('Tax', 'Asset', {'arrows': ['Tax', 'Asset'], 'marked': False}),
   ('P.E', 'P.B', {'arrows': ['P.E', 'P.E'], 'marked': False}),
   ('P.E', 'P.EBITDA', {'arrows': ['P.E', 'P.E'], 'marked': False}),
   ('Asset', 'Tobins.Q', {'arrows': ['Asset', 'Tobins.Q'], 'marked': False}),
   ('P.EBITDA',
    'Tobins.Q',
    {'arrows': ['Tobins.Q', 'Tobins.Q'], 'marked': False}),
   ('Tobins.Q', 'P.B', {'arrows': ['Tobins.Q'], 'marked': False})]
   }

I have yet to find a edge that meets Pearls criteria for causal inference.   

\clearpage

## causalTree
Efforts at implementing [https://github.com/susanathey/causalTree](https://github.com/susanathey/causalTree). 

Getting trees, which spx / AZS with the presense of an indep lead director and a financial leverage < 2.5)

```{r, echo=FALSE, fig.cap="CausalTree - spx / AZS / indepdirfincl", out.width = '100%'}
knitr::include_graphics("causalTree.png")
```

I'm having the same issue with this, in that I don't know what to include in the tree building process. I also still need to go over the validation of these trees. For example, 

  \textcolor{gray}{
    Node number 878: 85 observations \\
    causal effect=-0.6436914, error=13396.07\\ 
    Node number 879: 60 observations\\
    causal effect=-0.3289201, error=9465.907
  }
  
Those errors seem very high, but I don't understand what unit's they're in.

\clearpage

```{r, echo=FALSE, include=FALSE}
library(RMySQL)
library(knitr)
library(kableExtra)
```


```{r, echo=FALSE}
mydb <- dbConnect(MySQL(), user='root', password='', dbname='mm_results')
results.tobin <- dbReadTable(conn=mydb,name='tobin_q_results')
results.altman <- dbReadTable(conn=mydb,name='altman_z_results')
results.tobin$DateStamp <- NULL
results.altman$DateStamp <- NULL

kable(results.tobin, caption="MM Classification Results - Tobins Q as target") %>%
  kableExtra::landscape()

kable(results.altman, caption="MM Classification Results - Altman Z as target") %>%
  kableExtra::landscape()

```


```{r, echo=FALSE}
mydb <- dbConnect(MySQL(), user='root', password='', dbname='regression_results')
glmnet.results <- dbReadTable(conn=mydb,name='glmnet_results')

kable(glmnet.results, caption="Reg. Regression using Lasso Results") %>%
  kableExtra::landscape()

```


```{r, echo=FALSE}
mydb <- dbConnect(MySQL(), user='root', password='', dbname='causal_results')
akelleh.results <- dbReadTable(conn=mydb,name='akelleh_results_latest')

kable(akelleh.results, caption="akelleh Estimation Results") %>%
  kableExtra::landscape()

```

